{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNF1I5pDHjFAq1VKihvA4yB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rani-sikdar/GenAI-complete-course-codes/blob/main/text_similarity_metrices.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1. Cosine Similarity —\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "text1 = \"I love natural language processing\"  # Example sentences\n",
        "text2 = \"I enjoy learning about language and processing\"\n",
        "\n",
        "# Cosine similarity calculation using formula --\n",
        "vectorizer1 = CountVectorizer().fit([text1, text2])  # Convert to Bag of Words vectors\n",
        "vec1 = vectorizer1.transform([text1]).toarray()[0]\n",
        "vec2 = vectorizer1.transform([text2]).toarray()[0]\n",
        "\n",
        "cosine_similarity1 = np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
        "print(\"Cosine Similarity using formula :\", round(cosine_similarity1, 4))\n",
        "\n",
        "# # Cosine similarity using sklearn\n",
        "vectorizer2 = CountVectorizer().fit_transform([text1, text2])  # Vectorize the text\n",
        "vectors = vectorizer2.toarray()\n",
        "\n",
        "cosine_similarity2 = cosine_similarity([vectors[0]], [vectors[1]])\n",
        "print(\"Cosine Similarity usimg sklearn :\", round(cosine_similarity2[0][0], 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZqXmUKupRf4",
        "outputId": "84f58852-7f15-48f5-c44d-a9eae84a9186"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine Similarity using formula : 0.4082\n",
            "Cosine Similarity usimg sklearn : 0.4082\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2. Euclidean Distance —\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from scipy.spatial.distance import euclidean\n",
        "import numpy as np\n",
        "\n",
        "text1 = \"I love natural language processing\" # Example sentences\n",
        "text2 = \"I enjoy learning about language and processing\"\n",
        "\n",
        "# Euclidean Distance (Bag of Words)\n",
        "vectorizer1 = CountVectorizer().fit([text1, text2])   # Convert to vector\n",
        "vec1 = vectorizer1.transform([text1]).toarray()[0]\n",
        "vec2 = vectorizer1.transform([text2]).toarray()[0]\n",
        "\n",
        "euclidean_dist1 = np.linalg.norm(vec1 - vec2)\n",
        "print(\"Euclidean Distance (Bag of Words):\", round(euclidean_dist1, 4))\n",
        "\n",
        "# Euclidean Distance (scipy)\n",
        "vectorizer2 = CountVectorizer().fit([text1, text2])\n",
        "vecs = vectorizer2.transform([text1, text2]).toarray()\n",
        "\n",
        "euclidean_dist2 = euclidean(vecs[0], vecs[1])\n",
        "print(\"Euclidean Distance (scipy):\", round(euclidean_dist2, 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tReYGog2sj2O",
        "outputId": "2dd4afae-e210-4f48-c1bb-1a4b81dde909"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Euclidean Distance (Bag of Words): 2.4495\n",
            "Euclidean Distance (scipy): 2.4495\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0626dcf"
      },
      "source": [
        "# Download the spaCy model\n",
        "!python -m spacy download en_core_web_md"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3. Manhattan Distance\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import spacy\n",
        "import numpy as np\n",
        "\n",
        "text1 = \"I love natural language processing\" # Example Sentences\n",
        "text2 = \"I enjoy learning about language and processing\"\n",
        "\n",
        "# Manhattan Distance (Bag of Words)\n",
        "vectorizer = CountVectorizer().fit([text1, text2])  # Convert to Bag of Words\n",
        "vec1 = vectorizer.transform([text1]).toarray()[0]\n",
        "vec2 = vectorizer.transform([text2]).toarray()[0]\n",
        "\n",
        "manhattan_dist = np.sum(np.abs(vec1 - vec2))\n",
        "print(\"Manhattan Distance (Bag of Words) :\", manhattan_dist)\n",
        "\n",
        "# Manhattan Distance (spaCy)\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "\n",
        "doc1 = nlp(text1)\n",
        "doc2 = nlp(text2)\n",
        "\n",
        "# Manhattan Distance with dense embeddings\n",
        "manhattan = np.sum(np.abs(doc1.vector - doc2.vector))\n",
        "print(\"Manhattan Distance (spaCy):\", round(manhattan, 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nq66Ap4tgB8",
        "outputId": "b8947c7d-cca6-48cc-b1ff-b741bca35c0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manhattan Distance (Bag of Words) : 6\n",
            "Manhattan Distance (spaCy): 28.7481\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 4. Jaccard similairty\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import jaccard_score\n",
        "\n",
        "# Jaccard similarity (word-level)\n",
        "text1 = \"I love natural language processing\"\n",
        "text2 = \"I enjoy learning about language and processing\"\n",
        "\n",
        "set1 = set(text1.lower().split())  # Convert to sets of words (tokens)\n",
        "set2 = set(text2.lower().split())\n",
        "\n",
        "intersection = set1.intersection(set2)\n",
        "union = set1.union(set2)\n",
        "\n",
        "jaccard_similarity1 = len(intersection) / len(union)\n",
        "print(\"Jaccard Similarity (word-level):\", round(jaccard_similarity1, 4))\n",
        "\n",
        "# Jaccard Similarity using sklearn\n",
        "vectorizer = CountVectorizer(binary=True)\n",
        "X = vectorizer.fit_transform([text1, text2]).toarray()\n",
        "\n",
        "jaccard_similarity2 = jaccard_score(X[0], X[1])\n",
        "print(\"Jaccard Similarity (sklearn):\", round(jaccard_similarity2, 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvjkIcZAu3Pf",
        "outputId": "9c8cc008-dd4b-4b09-a26c-09814ad2a85f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jaccard Similarity (word-level): 0.3333\n",
            "Jaccard Similarity (sklearn): 0.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 5. Hamming Distance\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from scipy.spatial.distance import hamming\n",
        "\n",
        "text1 = \"I love to swim.\"\n",
        "text2 = \"I hate to swim.\"\n",
        "\n",
        "# Convert to binary vectors\n",
        "vectorizer = CountVectorizer(binary=True)\n",
        "X = vectorizer.fit_transform([text1, text2]).toarray()\n",
        "\n",
        "# Hamming distance\n",
        "dist = hamming(X[0], X[1])\n",
        "print(\"Hamming Distance :\", round(dist * len(X[0]), 2))  # actual differing count\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tSwOV7ov9nn",
        "outputId": "edea392f-6816-4660-8cf5-f654024a4ab9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hamming Distance : 2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h2fS57MixvEg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
