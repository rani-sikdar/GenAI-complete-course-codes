{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "552pulTaPvY0"
      },
      "outputs": [],
      "source": [
        "pip install langchain_community faiss-cpu openai langchain_community langchain-text-splitters langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install chromadb"
      ],
      "metadata": {
        "id": "h5sqFE_8SyU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain_chroma"
      ],
      "metadata": {
        "id": "hRj4aaZeT-PC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "OPENAI_API_KEY= \"sk------\"\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
      ],
      "metadata": {
        "id": "FvNFTdgHVHc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create sample vector db- Chroma\n",
        "\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_openai import OpenAIEmbeddings\n"
      ],
      "metadata": {
        "id": "Niq85vROSySo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title load the data\n",
        "\n",
        "loader = TextLoader('/content/speech.txt')\n",
        "docs = loader.load()"
      ],
      "metadata": {
        "id": "lqNoly68SyQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title split the data\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=20)\n",
        "splits = text_splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "_nYwEp5KSyNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title convert to vector store\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model =\"text-embedding-3-small\", openai_api_key= OPENAI_API_KEY)\n",
        "\n",
        "vector_db = Chroma.from_documents(documents= splits, embedding= embeddings)\n",
        "vector_db"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgetcymFSyKq",
        "outputId": "946d5a50-f9fb-4e0b-9ad3-b9084984623b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain_chroma.vectorstores.Chroma at 0x7f3b06d5ee50>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title query the vector db\n",
        "\n",
        "query =\"what is the main idea behind Continuous Skip-gram Model\"\n",
        "res = vector_db.similarity_search(query)\n",
        "res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gyz-ArU2SyH1",
        "outputId": "bef35ab6-1e7f-41e7-c06d-18b85deec2e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='9427ffda-7433-4ebf-aa97-3ee3b308e8ae', metadata={'source': '/content/speech.txt'}, page_content=\"b) Continuous Skip-gram Model\\nIdea: Predicts the surrounding context words given the current word. It's essentially the inverse of CBOW.\"),\n",
              " Document(id='32c8ee67-f12e-458e-91de-e380f5a6b9a2', metadata={'source': '/content/speech.txt'}, page_content=\"b) Continuous Skip-gram Model\\nIdea: Predicts the surrounding context words given the current word. It's essentially the inverse of CBOW.\"),\n",
              " Document(id='a24496ce-81d4-444b-9e96-702e3f72f8ca', metadata={'source': '/content/speech.txt'}, page_content='Performance: The paper found that Skip-gram generally works better for capturing semantic relationships, especially with large datasets, while CBOW can be faster to train.'),\n",
              " Document(id='bc24a62c-6f86-4101-b6c9-3ebdd5f86e17', metadata={'source': '/content/speech.txt'}, page_content='Performance: The paper found that Skip-gram generally works better for capturing semantic relationships, especially with large datasets, while CBOW can be faster to train.')]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res[0].page_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "rvYqpDMjSyE6",
        "outputId": "e6530273-abb5-4289-dfb3-742902c802b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"b) Continuous Skip-gram Model\\nIdea: Predicts the surrounding context words given the current word. It's essentially the inverse of CBOW.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Save vector store db in local\n",
        "\n",
        "vector_db = Chroma.from_documents(documents= splits, embedding= embeddings, persist_directory=\"/content/chroma_db\")"
      ],
      "metadata": {
        "id": "uZNg4QlGSyBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title load the vector db\n",
        "\n",
        "new_db = Chroma(persist_directory=\"/content/chroma_db\", embedding_function= embeddings)"
      ],
      "metadata": {
        "id": "Sv67AKWsWKtC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title user the loaded vector db\n",
        "\n",
        "result = new_db.similarity_search(query)\n",
        "result[3].page_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "id": "QCsAk7-JWm8x",
        "outputId": "6c3d0d73-23b6-43e6-8bd6-69dfd6d61a47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'simplified model architectures and clever optimization techniques like hierarchical softmax and negative sampling, which enabled training on unprecedentedly large text corpora.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " #@title similarity search with score\n",
        "\n",
        "result2 = new_db.similarity_search_with_score(query)\n",
        "result2[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4V_4-a4WxD7",
        "outputId": "5c9dc24e-bb1f-481d-ed57-0eec9f46b624"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Document(id='00b16cd0-7ed1-4f78-babf-1cde2c045842', metadata={'source': '/content/speech.txt'}, page_content=\"b) Continuous Skip-gram Model\\nIdea: Predicts the surrounding context words given the current word. It's essentially the inverse of CBOW.\"),\n",
              " 0.4862409234046936)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Retriever\n",
        "\n",
        "retriever = vector_db.as_retriever()\n",
        "retriever.invoke(query)[0].page_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "tDNdnzxoXFC-",
        "outputId": "8dce4056-12f6-4ecf-8565-95e7779a4a56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"b) Continuous Skip-gram Model\\nIdea: Predicts the surrounding context words given the current word. It's essentially the inverse of CBOW.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://python.langchain.com/docs/integrations/vectorstores/"
      ],
      "metadata": {
        "id": "wT9KjsSJXfY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k0G0e2bGo465"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}